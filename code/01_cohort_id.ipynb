{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import pyCLIF as pc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = pc.load_data('clif_adt')\n",
    "adt['hospitalization_id'] = adt['hospitalization_id'].astype(str)\n",
    "adt = pc.standardize_datetime_tz(adt,['in_dttm','out_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])\n",
    "adt['in_dttm'] = pc.getdttm(adt['in_dttm'])\n",
    "pc.deftime(adt['in_dttm'])\n",
    "adt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp = pc.load_data('clif_hospitalization')\n",
    "hosp['hospitalization_id'] = hosp['hospitalization_id'].astype(str)\n",
    "if 'hospitalization_joined_id' not in hosp.columns:\n",
    "    hosp['hospitalization_joined_id'] = hosp['hospitalization_id']\n",
    "\n",
    "hosp['hospitalization_joined_id'] = hosp['hospitalization_joined_id'].astype(str)\n",
    "hosp['admission_dttm'] = pc.getdttm(hosp['admission_dttm'])\n",
    "hosp['discharge_dttm'] = pc.getdttm(hosp['discharge_dttm'])\n",
    "hosp = pc.standardize_datetime_tz(hosp,['admission_dttm','discharge_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])\n",
    "hosp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt['Hosp_key_bkp'] = adt['hospitalization_id']\n",
    "hosp['Hosp_key_bkp'] = hosp['hospitalization_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eblock = pc.stitch_encounters(hosp,adt)\n",
    "\n",
    "# Create mapping dictionary\n",
    "hospitalization_to_block = {\n",
    "    hospital_id: block \n",
    "    for block, hospital_list in zip(eblock[\"encounter_block\"].astype(str), eblock[\"list_hospitalization_id\"])\n",
    "    for hospital_id in hospital_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rules_hosp = {\n",
    "    'patient_id': 'first',  # Assuming patient_id is consistent across duplicates\n",
    "    'zipcode_five_digit': 'first',  # Retain first occurrence\n",
    "    'admission_dttm': 'min',  # Earliest admission date\n",
    "    'discharge_dttm': 'max',  # Latest discharge date\n",
    "    'discharge_name': 'last',  # Prioritize first value (change as per logic)\n",
    "    'age_at_admission': 'mean',  # Take average if different\n",
    "    'discharge_category': 'last',  # Keep the first occurrence\n",
    "    'hospitalization_joined_id': lambda x: ', '.join(x.unique()),  # Retain first occurrence\n",
    "    'Hosp_key_bkp': lambda x: ', '.join(x.unique())  # Backup key, take first occurrence\n",
    "}\n",
    "\n",
    "hosp['hospitalization_id'] = hosp['hospitalization_id'].map(hospitalization_to_block)\n",
    "hosp['hospitalization_id'] = hosp['hospitalization_id'].astype(str)\n",
    "hosp = hosp.sort_values(by=['hospitalization_id', 'admission_dttm'])\n",
    "\n",
    "hosp = hosp.groupby('hospitalization_id').agg(agg_rules_hosp).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = adt[['hospitalization_id', 'in_dttm', 'location_category', 'hospital_id']]\n",
    "adt['hospitalization_id'] = adt['hospitalization_id'].map(hospitalization_to_block).astype(str)\n",
    "adt = adt.sort_values(by=['hospitalization_id', 'in_dttm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cohort filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pc.load_data('clif_respiratory_support')\n",
    "rst['hospitalization_id'] = rst['hospitalization_id'].astype(str)\n",
    "rst['hospitalization_id'] = rst['hospitalization_id'].map(hospitalization_to_block).fillna(-1).astype(int).astype(str)\n",
    "rst = rst[~rst['hospitalization_id'].isin(rst[rst['tracheostomy']==1].hospitalization_id.unique())] #exclude trach pats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pc.standardize_datetime_tz(rst,['recorded_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pc.load_data('clif_patient')\n",
    "pat = pc.standardize_datetime_tz(pat,['birth_date','death_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imv_hosp_ids = rst[rst['device_category'].str.lower()=='imv'].hospitalization_id.unique()\n",
    "icu_hosp_ids = adt[adt['location_category'].str.lower()=='icu'].hospitalization_id.unique()\n",
    "\n",
    "icu_hosp_ids = [x for x in icu_hosp_ids if x is not None]\n",
    "imv_hosp_ids = [x for x in imv_hosp_ids if x is not None]\n",
    "\n",
    "hosp = hosp[\n",
    "    (hosp['admission_dttm'].dt.year >= 2022) &\n",
    "    (hosp['admission_dttm'].dt.year <= 2024) &\n",
    "    (hosp['hospitalization_id'].isin(np.intersect1d(imv_hosp_ids, icu_hosp_ids))) &\n",
    "    (hosp['age_at_admission'] <=119)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "required_id= hosp['hospitalization_id'].unique()\n",
    "print(len(required_id),' : potential cohort count')\n",
    "\n",
    "base = pd.merge(hosp,pat,on='patient_id',how='inner')\\\n",
    "[['patient_id', 'hospitalization_id','admission_dttm', 'discharge_dttm','age_at_admission', 'discharge_category','sex_category','race_category', 'ethnicity_category']]\n",
    "\n",
    "base['admission_dttm'] = pc.getdttm(base['admission_dttm'])\n",
    "\n",
    "base.columns\n",
    "\n",
    "adt = adt[adt['hospitalization_id'].isin(required_id)].reset_index(drop=True)\n",
    "rst = rst[rst['hospitalization_id'].isin(required_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pc.helper['site_name']=='RUSH':\n",
    "    rst_col = [ 'hospitalization_id', 'recorded_dttm', 'device_category', 'mode_category','fio2_set','peep_set','resp_rate_set','pressure_support_set','mode_name','tube_comp_%','sbt_timepoint']\n",
    "else:\n",
    "    rst_col = [ 'hospitalization_id', 'recorded_dttm', 'device_category', 'mode_category','fio2_set','peep_set','resp_rate_set','pressure_support_set','mode_name']\n",
    "rst = rst[rst_col]\n",
    "rst['device_category'] = rst['device_category'].str.lower()\n",
    "rst['mode_category'] = rst['mode_category'].str.lower()\n",
    "rst['recorded_dttm'] = pc.getdttm(rst['recorded_dttm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.deftime(rst['recorded_dttm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = pc.load_data('clif_medication_admin_continuous')\n",
    "mac['hospitalization_id'] = mac['hospitalization_id'].astype(str)\n",
    "mac['hospitalization_id'] = mac['hospitalization_id'].map(hospitalization_to_block).astype(str)\n",
    "mac_col = ['hospitalization_id', 'admin_dttm','med_dose','med_category','med_dose_unit']\n",
    "mac = mac[(mac['hospitalization_id'].isin(required_id)) & (mac['med_category'].isin( [\n",
    "        \"norepinephrine\",\n",
    "        \"epinephrine\",\n",
    "        \"phenylephrine\",\n",
    "        \"angiotensin\",\n",
    "        \"vasopressin\",\n",
    "        \"dopamine\",\n",
    "        \"dobutamine\",\n",
    "        \"milrinone\",\n",
    "        \"isoproterenol\",\n",
    "        \"cisatracurium\",\n",
    "        \"vecuronium\",\n",
    "        \"rocuronium\",'fentanyl', 'propofol', 'lorazepam', 'midazolam','hydromorphone','morphine'\n",
    "    ]))][mac_col].reset_index(drop=True)\n",
    "\n",
    "mac['admin_dttm'] = pc.getdttm(mac['admin_dttm'])\n",
    "mac = pc.standardize_datetime_tz(mac,['admin_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])\n",
    "\n",
    "mac['med_dose_unit']=mac['med_dose_unit'].str.lower()\n",
    "mac = mac[(mac['med_dose_unit'].str.contains(r'/', na=False)) & (mac['med_dose_unit']!='units/hr')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_values_mapping_dict = {\n",
    "    'negative': 0,\n",
    "    'fail': 0,\n",
    "    'pass': 1,\n",
    "    'positive': 1,\n",
    "    None: np.nan ,\n",
    "    np.nan : np.nan,\n",
    "    'yes':1,\n",
    "    'no':0\n",
    "}\n",
    "\n",
    "pat_assess_cats_rquired = [ 'sbt_delivery_pass_fail',\n",
    "                            'sbt_screen_pass_fail','sat_delivery_pass_fail',\n",
    "                            'sat_screen_pass_fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at = pc.load_data('clif_patient_assessments',-1)\n",
    "pat_at_col = ['hospitalization_id', 'recorded_dttm','numerical_value', 'categorical_value','assessment_category']\n",
    "pat_at['assessment_category'] = pat_at['assessment_category'].str.lower()\n",
    "pat_at = pat_at[(pat_at['assessment_category'].isin(pat_assess_cats_rquired)) ][pat_at_col].reset_index(drop=True)\n",
    "pat_at = pc.standardize_datetime_tz(pat_at,['recorded_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at['hospitalization_id'] = pat_at['hospitalization_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at['hospitalization_id'] = pat_at['hospitalization_id'].map(hospitalization_to_block).fillna(-1).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at = pat_at[(pat_at['hospitalization_id'].isin(required_id))][pat_at_col].reset_index(drop=True)\n",
    "pat_at['recorded_dttm'] = pc.getdttm(pat_at['recorded_dttm'])\n",
    "pat_at['categorical_value'] = pat_at['categorical_value'].str.lower().map(cat_values_mapping_dict)\n",
    "pat_at['assessment_value'] = pat_at['numerical_value'].combine_first(pat_at['categorical_value'])\n",
    "pat_at.drop(columns=['numerical_value','categorical_value'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at.assessment_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at['assessment_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = pc.load_data('clif_vitals',-1)\n",
    "vit['hospitalization_id'] = vit['hospitalization_id'].astype(str)\n",
    "vit['hospitalization_id'] = vit['hospitalization_id'].map(hospitalization_to_block).astype(str)\n",
    "vit_col = ['hospitalization_id','recorded_dttm','vital_category','vital_value' ]\n",
    "vit['vital_category'] = vit['vital_category'].str.lower()\n",
    "vit = pc.standardize_datetime_tz(vit,['recorded_dttm'],pc.helper['your_site_timezone'],pc.helper['data_timezone'])\n",
    "vit = vit[(vit['hospitalization_id'].isin(required_id)) & (vit['vital_category'].isin(['map','heart_rate','sbp','dbp','spo2','respiratory_rate','weight_kg','height_cm'])) ][vit_col].reset_index(drop=True)\n",
    "\n",
    "vit['recorded_dttm_min'] = pc.getdttm(vit['recorded_dttm'])\n",
    "\n",
    "# Sort by hospitalization_id and recorded_dttm\n",
    "vit = vit.sort_values(by=[\"hospitalization_id\", \"recorded_dttm\"])\n",
    "\n",
    "# Group by hospitalization_id, vital_category, and recorded_dttm_min, then take the first occurrence of vital_value\n",
    "vit = vit.groupby([\"hospitalization_id\", \"vital_category\", \"recorded_dttm_min\"], as_index=False).agg({\n",
    "    \"vital_value\": \"first\"\n",
    "})\n",
    "# make sure float\n",
    "vit['vital_value']=vit['vital_value'].astype(float)\n",
    "\n",
    "#for meds\n",
    "vit_weight = vit[vit['vital_category']=='weight_kg'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates\n",
    "duplicates = vit.duplicated(subset=[\"hospitalization_id\", \"vital_category\", \"recorded_dttm_min\"], keep=False)\n",
    "\n",
    "# Show any duplicates (should be empty if grouping worked correctly)\n",
    "vit[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new mac and weight df for med unit conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weight.rename({'vital_category': 'med_category', 'recorded_dttm_min': 'admin_dttm'}, axis='columns', inplace=True)\n",
    "\n",
    "new_mac = pd.concat([mac, vit_weight], ignore_index=True)\n",
    "\n",
    "new_mac = new_mac.sort_values(by=['hospitalization_id', 'admin_dttm'])\n",
    "\n",
    "new_mac['vital_value'] = new_mac.groupby('hospitalization_id')['vital_value'].ffill().bfill()\n",
    "\n",
    "new_mac = new_mac[~(new_mac['med_category']=='weight_kg')].reset_index(drop=True)\n",
    "\n",
    "print('mac rows:',mac.shape,'New mac rows:', new_mac.shape)\n",
    "#del vit_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mac.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The med_unit_info dictionary\n",
    "med_unit_info = {\n",
    "    'norepinephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'epinephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'phenylephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'angiotensin': {\n",
    "        'required_unit': 'ng/kg/min',\n",
    "        'acceptable_units': ['ng/kg/min', 'ng/kg/hr'],\n",
    "    },\n",
    "    'vasopressin': {\n",
    "        'required_unit': 'units/min',\n",
    "        'acceptable_units': ['units/min', 'units/hr', 'milliunits/min', 'milliunits/hr'],\n",
    "    },\n",
    "    'dopamine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'dobutamine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'milrinone': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'isoproterenol': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "}\n",
    "\n",
    "def convert_med_dose(row):\n",
    "    category = row['med_category']\n",
    "    # If the category is not in our dictionary, skip conversion.\n",
    "    if category not in med_unit_info:\n",
    "        return row\n",
    "    \n",
    "    info = med_unit_info[category]\n",
    "    required_unit = info['required_unit']\n",
    "    acceptable_units = info['acceptable_units']\n",
    "    \n",
    "    current_unit = row['med_dose_unit']\n",
    "    dose = row['med_dose']\n",
    "    weight = row['vital_value']  # patient's weight in kg\n",
    "\n",
    "    # If the current unit already matches the required unit, nothing to do.\n",
    "    if current_unit == required_unit:\n",
    "        return row\n",
    "\n",
    "    # If the current unit is not in the acceptable list, skip conversion.\n",
    "    if current_unit not in acceptable_units:\n",
    "        return row\n",
    "\n",
    "    # Start with a conversion factor of 1.\n",
    "    conversion_factor = 1.0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Weight conversion: if the current unit is per kg but the required is not,\n",
    "    # then multiply by the patientâ€™s weight.\n",
    "    if 'kg' in current_unit and 'kg' not in required_unit:\n",
    "        conversion_factor *= weight\n",
    "    elif 'kg' not in current_unit and 'kg' in required_unit:\n",
    "        conversion_factor /= weight\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Time conversion: convert from per hour to per minute or vice versa.\n",
    "    if 'hr' in current_unit and 'min' in required_unit:\n",
    "        conversion_factor /= 60.0\n",
    "    elif 'min' in current_unit and 'hr' in required_unit:\n",
    "        conversion_factor *= 60.0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Medication unit conversion (e.g., mg to mcg, milliunits to units)\n",
    "    # We assume the first part (before the first '/') is the measurement unit.\n",
    "    current_med_unit = current_unit.split('/')[0]\n",
    "    required_med_unit = required_unit.split('/')[0]\n",
    "\n",
    "    med_conversion = {\n",
    "        ('mg', 'mcg'): 1000,\n",
    "        ('mcg', 'mg'): 0.001,\n",
    "        ('milliunits', 'units'): 0.001,\n",
    "        ('units', 'milliunits'): 1000,\n",
    "    }\n",
    "\n",
    "    if current_med_unit != required_med_unit:\n",
    "        factor = med_conversion.get((current_med_unit, required_med_unit))\n",
    "        if factor is not None:\n",
    "            conversion_factor *= factor\n",
    "        else:\n",
    "            # If no conversion factor is defined, skip conversion.\n",
    "            return row\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Apply the conversion\n",
    "    new_dose = dose * conversion_factor\n",
    "\n",
    "    # Update the row with the converted dose and unit.\n",
    "    row['med_dose'] = new_dose\n",
    "    row['med_dose_unit'] = required_unit\n",
    "    return row\n",
    "\n",
    "# Apply the conversion function with tqdm for progress tracking\n",
    "tqdm.pandas(desc=\"Converting medication doses\")\n",
    "new_mac = new_mac.progress_apply(convert_med_dose, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table for each med_category\n",
    "summary_table = new_mac.groupby(['med_category','med_dose_unit']).agg(\n",
    "    total_N=('med_category', 'size'),\n",
    "    min=('med_dose', 'min'),\n",
    "    max=('med_dose', 'max'),\n",
    "    first_quantile=('med_dose', lambda x: x.quantile(0.25)),\n",
    "    second_quantile=('med_dose', lambda x: x.quantile(0.5)),\n",
    "    third_quantile=('med_dose', lambda x: x.quantile(0.75)),\n",
    "    missing_values=('med_dose', lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "## check the distrbituon of required continuous meds\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.register(\"base\", base)\n",
    "duckdb.register(\"pat_at\", pat_at)\n",
    "duckdb.register(\"rst\", rst)\n",
    "duckdb.register(\"mac\", new_mac)\n",
    "duckdb.register('adt',adt)\n",
    "duckdb.register('vit',vit)\n",
    "\n",
    "q=\"\"\"\n",
    "WITH\n",
    "    uni_event_dttm as (\n",
    "        select distinct\n",
    "            hospitalization_id,\n",
    "            event_time\n",
    "        from\n",
    "            (\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    in_dttm AS event_time\n",
    "                FROM\n",
    "                    adt\n",
    "                where\n",
    "                    in_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm AS event_time\n",
    "                FROM\n",
    "                    rst\n",
    "                where\n",
    "                    recorded_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm AS event_time\n",
    "                FROM\n",
    "                    pat_at\n",
    "                where\n",
    "                    recorded_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    admin_dttm AS event_time\n",
    "                FROM\n",
    "                    mac\n",
    "                where\n",
    "                    admin_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm_min AS event_time\n",
    "                FROM\n",
    "                    vit\n",
    "                where\n",
    "                    recorded_dttm_min is not null\n",
    "            ) uni_time\n",
    "    )\n",
    "select distinct\n",
    "    patient_id,\n",
    "    a.hospitalization_id,\n",
    "    admission_dttm,\n",
    "    discharge_dttm,\n",
    "    age_at_admission,\n",
    "    discharge_category,\n",
    "    sex_category,\n",
    "    race_category,\n",
    "    ethnicity_category,\n",
    "    event_time\n",
    "from\n",
    "    base a\n",
    "    left join uni_event_dttm b on a.hospitalization_id = b.hospitalization_id\n",
    "\"\"\"\n",
    "wide_cohort_df = duckdb.sql(q).df()\n",
    "pc.deftime(wide_cohort_df['event_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pivots for assessment and mac table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH pas_data AS (\n",
    "    SELECT  distinct assessment_value ,\tassessment_category\t,\n",
    "    hospitalization_id || '_' || strftime(recorded_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM pat_at where recorded_dttm is not null \n",
    ") \n",
    "PIVOT pas_data\n",
    "ON assessment_category\n",
    "USING first(assessment_value)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_pas = duckdb.sql(query).df()\n",
    "\n",
    "query = \"\"\"\n",
    "WITH mac_data AS (\n",
    "    SELECT  distinct med_dose ,\tmed_category\t,\n",
    "    hospitalization_id || '_' || strftime(admin_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM mac where admin_dttm is not null \n",
    ") \n",
    "PIVOT mac_data\n",
    "ON med_category\n",
    "USING min(med_dose)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_mac = duckdb.sql(query).df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "WITH vital_data AS (\n",
    "    SELECT  distinct vital_category,\tvital_value\t,\n",
    "    hospitalization_id || '_' || strftime(recorded_dttm_min, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM vit where recorded_dttm_min is not null \n",
    ")\n",
    "PIVOT vital_data\n",
    "ON vital_category\n",
    "USING first(vital_value)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_vitals = duckdb.sql(query).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id-ing all unique timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.register(\"expanded_df\", wide_cohort_df)\n",
    "duckdb.register(\"p_pas\", p_pas)\n",
    "duckdb.register(\"p_mac\", p_mac)\n",
    "\n",
    "q=\"\"\"\n",
    "  WITH\n",
    "    u_rst as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (recorded_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            rst\n",
    "    ),\n",
    "    u_adt as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (in_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            adt\n",
    "    ),\n",
    "    u_expanded_df as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (event_time, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            expanded_df\n",
    "    )\n",
    "select\n",
    "    *\n",
    "from\n",
    "    u_expanded_df a\n",
    "    left join u_adt d on a.combo_id = d.combo_id\n",
    "    left join u_rst e on a.combo_id = e.combo_id\n",
    "    left join p_mac g on a.combo_id = g.combo_id\n",
    "    left join p_pas h on a.combo_id = h.combo_id\n",
    "    left join p_vitals i on a.combo_id=i.combo_id \n",
    "\n",
    "                    \n",
    "\"\"\"\n",
    "\n",
    "all_join_df = duckdb.sql(q).df().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_join_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cohort_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_join_df.shape[0] != wide_cohort_df.shape[0]:\n",
    "    print('Data has duplicates or same timestamp issue, contact project owner')\n",
    "else:\n",
    "    del rst,mac,pat_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing wide-supporting columns and adding forward fills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_join_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_join_df.drop(columns= ['hospitalization_id_2','hospitalization_id_3','combo_id', 'combo_id_2' ,'combo_id_3','combo_id_4','combo_id_5','recorded_dttm','combo_id_6','in_dttm'], axis = 1,inplace=True)\n",
    "\n",
    "all_join_df['event_time'] = pd.to_datetime(all_join_df['event_time'])\n",
    "all_join_df['date'] = all_join_df['event_time'].dt.date\n",
    "\n",
    "all_join_df = all_join_df.sort_values(['hospitalization_id', 'event_time']).reset_index(drop=True)\n",
    "\n",
    "# Assign day numbers to each 'hospitalization_id'\n",
    "all_join_df['day_number'] = all_join_df.groupby('hospitalization_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "# Create the combo_key by combining 'hospitalization_id' and 'day_number'\n",
    "all_join_df['hosp_id_day_key'] = all_join_df['hospitalization_id'].astype(str) + '_day_' + all_join_df['day_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['sbt_delivery_pass_fail','sbt_screen_pass_fail','sat_delivery_pass_fail','sat_screen_pass_fail']\n",
    "for col in columns_to_check:\n",
    "    if col not in all_join_df.columns:\n",
    "        all_join_df[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pc.helper['site_name']=='RUSH':\n",
    "    all_join_df[['patient_id',\n",
    " 'hospitalization_id',\n",
    " 'admission_dttm',\n",
    " 'discharge_dttm',\n",
    " 'age_at_admission',\n",
    " 'discharge_category',\n",
    " 'sex_category',\n",
    " 'race_category',\n",
    " 'ethnicity_category',\n",
    " 'event_time',\n",
    " 'location_category',\n",
    " 'hospital_id',\n",
    " 'recorded_dttm',\n",
    " 'device_category',\n",
    " 'mode_category',\n",
    " 'fio2_set',\n",
    " 'peep_set',\n",
    " 'resp_rate_set',\n",
    " 'pressure_support_set',\n",
    " 'mode_name',\n",
    " 'tube_comp_%',\n",
    " 'sbt_timepoint',\n",
    " 'cisatracurium',\n",
    " 'dobutamine',\n",
    " 'dopamine',\n",
    " 'epinephrine',\n",
    " 'fentanyl',\n",
    " 'hydromorphone',\n",
    " 'midazolam',\n",
    " 'milrinone',\n",
    " 'morphine',\n",
    " 'norepinephrine',\n",
    " 'phenylephrine',\n",
    " 'propofol',\n",
    " 'vasopressin',\n",
    " 'sat_delivery_pass_fail',\n",
    " 'sat_screen_pass_fail',\n",
    " 'sbt_delivery_pass_fail',\n",
    " 'sbt_screen_pass_fail',\n",
    " 'dbp',\n",
    " 'heart_rate',\n",
    " 'height_cm',\n",
    " 'map',\n",
    " 'respiratory_rate',\n",
    " 'sbp',\n",
    " 'spo2',\n",
    " 'weight_kg',\n",
    " 'date',\n",
    " 'day_number',\n",
    " 'hosp_id_day_key']].to_csv('../output/intermediate/study_cohort.csv', index=False)\n",
    "else:\n",
    "    all_join_df[['patient_id',\n",
    " 'hospitalization_id',\n",
    " 'admission_dttm',\n",
    " 'discharge_dttm',\n",
    " 'age_at_admission',\n",
    " 'discharge_category',\n",
    " 'sex_category',\n",
    " 'race_category',\n",
    " 'ethnicity_category',\n",
    " 'event_time',\n",
    " 'location_category',\n",
    " 'hospital_id',\n",
    " 'recorded_dttm',\n",
    " 'device_category',\n",
    " 'mode_category',\n",
    " 'fio2_set',\n",
    " 'peep_set',\n",
    " 'resp_rate_set',\n",
    " 'pressure_support_set',\n",
    " 'mode_name',\n",
    " 'cisatracurium',\n",
    " 'dobutamine',\n",
    " 'dopamine',\n",
    " 'epinephrine',\n",
    " 'fentanyl',\n",
    " 'hydromorphone',\n",
    " 'midazolam',\n",
    " 'milrinone',\n",
    " 'morphine',\n",
    " 'norepinephrine',\n",
    " 'phenylephrine',\n",
    " 'propofol',\n",
    " 'vasopressin',\n",
    " 'sat_delivery_pass_fail',\n",
    " 'sat_screen_pass_fail',\n",
    " 'sbt_delivery_pass_fail',\n",
    " 'sbt_screen_pass_fail',\n",
    " 'dbp',\n",
    " 'heart_rate',\n",
    " 'height_cm',\n",
    " 'map',\n",
    " 'respiratory_rate',\n",
    " 'sbp',\n",
    " 'spo2',\n",
    " 'weight_kg',\n",
    " 'date',\n",
    " 'day_number',\n",
    " 'hosp_id_day_key']].to_csv('../output/intermediate/study_cohort.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".SBT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
