{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pytz\n",
    "import duckdb\n",
    "import pyCLIF as pc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = pc.load_data(\"clif_adt\")\n",
    "adt[\"hospitalization_id\"] = adt[\"hospitalization_id\"].astype(str)\n",
    "adt = pc.convert_datetime_columns_to_site_tz(adt, pc.helper[\"your_site_timezone\"])\n",
    "adt[\"in_dttm\"] = pc.getdttm(adt[\"in_dttm\"])\n",
    "pc.deftime(adt[\"in_dttm\"])\n",
    "adt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hospitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp = pc.load_data(\"clif_hospitalization\")\n",
    "hosp[\"hospitalization_id\"] = hosp[\"hospitalization_id\"].astype(str)\n",
    "if \"hospitalization_joined_id\" not in hosp.columns:\n",
    "    hosp[\"hospitalization_joined_id\"] = hosp[\"hospitalization_id\"]\n",
    "\n",
    "hosp[\"hospitalization_joined_id\"] = hosp[\"hospitalization_joined_id\"].astype(str)\n",
    "\n",
    "hosp = pc.convert_datetime_columns_to_site_tz(hosp, pc.helper[\"your_site_timezone\"])\n",
    "hosp[\"admission_dttm\"] = pc.getdttm(hosp[\"admission_dttm\"])\n",
    "hosp[\"discharge_dttm\"] = pc.getdttm(hosp[\"discharge_dttm\"])\n",
    "\n",
    "adt[\"Hosp_key_bkp\"] = adt[\"hospitalization_id\"]\n",
    "hosp[\"Hosp_key_bkp\"] = hosp[\"hospitalization_id\"]\n",
    "\n",
    "hosp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hospitalization Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eblock = pc.stitch_encounters(hosp, adt)\n",
    "\n",
    "# Create mapping dictionary\n",
    "hospitalization_to_block = {\n",
    "    hospital_id: block\n",
    "    for block, hospital_list in zip(\n",
    "        eblock[\"encounter_block\"].astype(str), eblock[\"list_hospitalization_id\"]\n",
    "    )\n",
    "    for hospital_id in hospital_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "hospitalization_to_block_df = pd.DataFrame(\n",
    "    list(hospitalization_to_block.items()),\n",
    "    columns=[\"hospitalization_id\", \"encounter_block\"],\n",
    ")\n",
    "hospitalization_to_block_df.to_csv(\n",
    "    \"../output/intermediate/hospitalization_to_block_df.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rules_hosp = {\n",
    "    \"patient_id\": \"first\",  # Assuming patient_id is consistent across duplicates\n",
    "    \"zipcode_five_digit\": \"first\",  # Retain first occurrence\n",
    "    \"admission_dttm\": \"min\",  # Earliest admission date\n",
    "    \"discharge_dttm\": \"max\",  # Latest discharge date\n",
    "    \"discharge_name\": \"last\",  # Prioritize first value (change as per logic)\n",
    "    \"age_at_admission\": \"mean\",  # Take average if different\n",
    "    \"discharge_category\": \"last\",  # Keep the first occurrence\n",
    "    \"hospitalization_joined_id\": lambda x: \", \".join(\n",
    "        x.unique()\n",
    "    ),  # Retain first occurrence\n",
    "    \"Hosp_key_bkp\": lambda x: \", \".join(\n",
    "        x.unique()\n",
    "    ),  # Backup key, take first occurrence\n",
    "}\n",
    "\n",
    "hosp[\"hospitalization_id\"] = hosp[\"hospitalization_id\"].map(hospitalization_to_block)\n",
    "hosp[\"hospitalization_id\"] = hosp[\"hospitalization_id\"].astype(str)\n",
    "hosp = hosp.sort_values(by=[\"hospitalization_id\", \"admission_dttm\"])\n",
    "\n",
    "hosp = hosp.groupby(\"hospitalization_id\").agg(agg_rules_hosp).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = adt[[\"hospitalization_id\", \"in_dttm\", \"location_category\", \"hospital_id\"]]\n",
    "adt[\"hospitalization_id\"] = (\n",
    "    adt[\"hospitalization_id\"].map(hospitalization_to_block).astype(str)\n",
    ")\n",
    "adt = adt.sort_values(by=[\"hospitalization_id\", \"in_dttm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respiratory Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pc.load_data(\"clif_respiratory_support\")\n",
    "rst[\"hospitalization_id\"] = rst[\"hospitalization_id\"].astype(str)\n",
    "rst[\"hospitalization_id\"] = (\n",
    "    rst[\"hospitalization_id\"]\n",
    "    .map(hospitalization_to_block)\n",
    "    .fillna(-1)\n",
    "    .astype(int)\n",
    "    .astype(str)\n",
    ")\n",
    "rst = rst[\n",
    "    ~rst[\"hospitalization_id\"].isin(\n",
    "        rst[rst[\"tracheostomy\"] == 1].hospitalization_id.unique()\n",
    "    )\n",
    "]  # exclude trach pats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = pc.convert_datetime_columns_to_site_tz(rst, pc.helper[\"your_site_timezone\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pc.load_data(\"clif_patient\")\n",
    "pat = pc.convert_datetime_columns_to_site_tz(pat, pc.helper[\"your_site_timezone\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohort Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imv_hosp_ids = rst[\n",
    "    rst[\"device_category\"].str.lower() == \"imv\"\n",
    "].hospitalization_id.unique()\n",
    "icu_hosp_ids = adt[\n",
    "    adt[\"location_category\"].str.lower() == \"icu\"\n",
    "].hospitalization_id.unique()\n",
    "\n",
    "icu_hosp_ids = [x for x in icu_hosp_ids if x is not None]\n",
    "imv_hosp_ids = [x for x in imv_hosp_ids if x is not None]\n",
    "\n",
    "hosp = hosp[\n",
    "    (hosp[\"admission_dttm\"].dt.year >= 2022)\n",
    "    & (hosp[\"admission_dttm\"].dt.year <= 2024)\n",
    "    & (hosp[\"discharge_dttm\"].dt.year <= 2024)\n",
    "    & (hosp[\"hospitalization_id\"].isin(np.intersect1d(imv_hosp_ids, icu_hosp_ids)))\n",
    "    & (hosp[\"age_at_admission\"] >= 18)\n",
    "    & (hosp[\"age_at_admission\"] <= 119)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "required_id = hosp[\"hospitalization_id\"].unique()\n",
    "print(len(required_id), \" : potential cohort count\")\n",
    "\n",
    "base = pd.merge(hosp, pat, on=\"patient_id\", how=\"inner\")[\n",
    "    [\n",
    "        \"patient_id\",\n",
    "        \"hospitalization_id\",\n",
    "        \"admission_dttm\",\n",
    "        \"discharge_dttm\",\n",
    "        \"age_at_admission\",\n",
    "        \"discharge_category\",\n",
    "        \"sex_category\",\n",
    "        \"race_category\",\n",
    "        \"ethnicity_category\",\n",
    "        \"language_name\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "base[\"admission_dttm\"] = pc.getdttm(base[\"admission_dttm\"])\n",
    "\n",
    "base.columns\n",
    "\n",
    "adt = adt[adt[\"hospitalization_id\"].isin(required_id)].reset_index(drop=True)\n",
    "rst = rst[rst[\"hospitalization_id\"].isin(required_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water Fall Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aswaterfallneedinutc\n",
    "rst['recorded_dttm'] = rst['recorded_dttm'].dt.tz_convert('UTC')\n",
    "\n",
    "new_rst = pc.process_resp_support_waterfall(rst)\n",
    "new_rst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rst['recorded_dttm'] = new_rst['recorded_dttm'].dt.tz_convert(pc.helper['your_site_timezone'])\n",
    "rst = new_rst.copy()\n",
    "\n",
    "rst[\"recorded_dttm\"] = pc.getdttm(rst[\"recorded_dttm\"])\n",
    "pc.deftime(rst[\"recorded_dttm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "water fall end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pc.helper[\"site_name\"] == \"RUSH\":\n",
    "    rst_col = [\n",
    "        \"hospitalization_id\",\n",
    "        \"recorded_dttm\",\n",
    "        \"device_category\",\n",
    "        \"mode_category\",\n",
    "        \"fio2_set\",\n",
    "        \"peep_set\",\n",
    "        \"resp_rate_set\",\n",
    "        \"pressure_support_set\",\n",
    "        \"mode_name\",\n",
    "        \"tube_comp_%\",\n",
    "        \"sbt_timepoint\",\n",
    "        \"vent_brand_name\",\n",
    "    ]\n",
    "    rst[\"device_category\"] = rst[\"device_category\"].replace(\"nan\", np.nan)\n",
    "else:\n",
    "    rst_col = [\n",
    "        \"hospitalization_id\",\n",
    "        \"recorded_dttm\",\n",
    "        \"device_category\",\n",
    "        \"mode_category\",\n",
    "        \"fio2_set\",\n",
    "        \"peep_set\",\n",
    "        \"resp_rate_set\",\n",
    "        \"pressure_support_set\",\n",
    "        \"mode_name\",\n",
    "        \"vent_brand_name\",\n",
    "    ]\n",
    "rst = rst[rst_col]\n",
    "rst[\"device_category\"] = rst[\"device_category\"].str.lower()\n",
    "rst[\"mode_category\"] = rst[\"mode_category\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extubated Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort and forward-fill device_category by hospitalization_id\n",
    "rst = rst.sort_values([\"hospitalization_id\", \"recorded_dttm\"])\n",
    "rst[\"device_category\"] = rst.groupby(\"hospitalization_id\")[\"device_category\"].ffill()\n",
    "\n",
    "# Step 2: Create a device_segment_id for each change in device_category within a hospitalization\n",
    "rst[\"device_change\"] = (\n",
    "    rst[\"device_category\"]\n",
    "    != rst.groupby(\"hospitalization_id\")[\"device_category\"].shift()\n",
    ").astype(int)\n",
    "rst[\"device_segment_id\"] = rst.groupby(\"hospitalization_id\")[\"device_change\"].cumsum()\n",
    "\n",
    "# Step 3: Forward-fill mode_category within each device_segment_id and hospitalization_id\n",
    "rst[\"mode_category\"] = rst.groupby([\"hospitalization_id\", \"device_segment_id\"])[\n",
    "    \"mode_category\"\n",
    "].ffill()\n",
    "\n",
    "# Step 4: Create Device_IMV column\n",
    "rst[\"Device_IMV\"] = (rst[\"device_category\"] == \"imv\").astype(int)\n",
    "\n",
    "# Step 5: Flag extubation when there's a switch from IMV to two consecutive non-IMV entries\n",
    "rst[\"extubated\"] = 0\n",
    "for hosp_id, group in tqdm(rst.groupby(\"hospitalization_id\")):\n",
    "    group = group.sort_values(\"recorded_dttm\")\n",
    "    idx = group.index\n",
    "    for i in range(len(group) - 2):\n",
    "        if (\n",
    "            group.iloc[i][\"Device_IMV\"] == 1\n",
    "            and group.iloc[i + 1][\"Device_IMV\"] == 0\n",
    "            and group.iloc[i + 2][\"Device_IMV\"] == 0\n",
    "        ):\n",
    "            rst.at[idx[i], \"extubated\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = pc.load_data(\"clif_medication_admin_continuous\")\n",
    "mac[\"hospitalization_id\"] = mac[\"hospitalization_id\"].astype(str)\n",
    "mac[\"hospitalization_id\"] = (\n",
    "    mac[\"hospitalization_id\"].map(hospitalization_to_block).astype(str)\n",
    ")\n",
    "mac_col = [\n",
    "    \"hospitalization_id\",\n",
    "    \"admin_dttm\",\n",
    "    \"med_dose\",\n",
    "    \"med_category\",\n",
    "    \"med_dose_unit\",\n",
    "]\n",
    "mac = mac[\n",
    "    (mac[\"hospitalization_id\"].isin(required_id))\n",
    "    & (\n",
    "        mac[\"med_category\"].isin(\n",
    "            [\n",
    "                \"norepinephrine\",\n",
    "                \"epinephrine\",\n",
    "                \"phenylephrine\",\n",
    "                \"angiotensin\",\n",
    "                \"vasopressin\",\n",
    "                \"dopamine\",\n",
    "                \"dobutamine\",\n",
    "                \"milrinone\",\n",
    "                \"isoproterenol\",\n",
    "                \"cisatracurium\",\n",
    "                \"vecuronium\",\n",
    "                \"rocuronium\",\n",
    "                \"fentanyl\",\n",
    "                \"propofol\",\n",
    "                \"lorazepam\",\n",
    "                \"midazolam\",\n",
    "                \"hydromorphone\",\n",
    "                \"morphine\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "][mac_col].reset_index(drop=True)\n",
    "\n",
    "\n",
    "mac = pc.convert_datetime_columns_to_site_tz(mac, pc.helper[\"your_site_timezone\"])\n",
    "mac[\"admin_dttm\"] = pc.getdttm(mac[\"admin_dttm\"])\n",
    "\n",
    "mac[\"med_dose_unit\"] = mac[\"med_dose_unit\"].str.lower()\n",
    "mac = mac[\n",
    "    (mac[\"med_dose_unit\"].str.contains(r\"/\", na=False))\n",
    "    & (mac[\"med_dose_unit\"] != \"units/hr\")\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.deftime(mac['admin_dttm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_values_mapping_dict = {\n",
    "    \"negative\": 0,\n",
    "    \"fail\": 0,\n",
    "    \"pass\": 1,\n",
    "    \"positive\": 1,\n",
    "    None: np.nan,\n",
    "    np.nan: np.nan,\n",
    "    \"yes\": 1,\n",
    "    \"no\": 0,\n",
    "}\n",
    "\n",
    "pat_assess_cats_rquired = [\n",
    "    \"sbt_delivery_pass_fail\",\n",
    "    \"sbt_screen_pass_fail\",\n",
    "    \"sat_delivery_pass_fail\",\n",
    "    \"sat_screen_pass_fail\",\n",
    "    \"gcs_total\",\n",
    "    \"rass\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at = pc.load_data(\"clif_patient_assessments\", -1)\n",
    "pat_at_col = [\n",
    "    \"hospitalization_id\",\n",
    "    \"recorded_dttm\",\n",
    "    \"numerical_value\",\n",
    "    \"categorical_value\",\n",
    "    \"assessment_category\",\n",
    "]\n",
    "pat_at[\"assessment_category\"] = pat_at[\"assessment_category\"].str.lower()\n",
    "pat_at = pat_at[(pat_at[\"assessment_category\"].isin(pat_assess_cats_rquired))][\n",
    "    pat_at_col\n",
    "].reset_index(drop=True)\n",
    "\n",
    "pat_at = pc.convert_datetime_columns_to_site_tz(pat_at, pc.helper[\"your_site_timezone\"])\n",
    "pat_at[\"recorded_dttm\"] = pc.getdttm(pat_at[\"recorded_dttm\"])\n",
    "pc.deftime(pat_at[\"recorded_dttm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at[\"hospitalization_id\"] = pat_at[\"hospitalization_id\"].astype(str)\n",
    "pat_at[\"hospitalization_id\"] = (\n",
    "    pat_at[\"hospitalization_id\"]\n",
    "    .map(hospitalization_to_block)\n",
    "    .fillna(-1)\n",
    "    .astype(int)\n",
    "    .astype(str)\n",
    ")\n",
    "\n",
    "pat_at = pat_at[(pat_at[\"hospitalization_id\"].isin(required_id))][\n",
    "    pat_at_col\n",
    "].reset_index(drop=True)\n",
    "pat_at[\"categorical_value\"] = (\n",
    "    pat_at[\"categorical_value\"].str.lower().map(cat_values_mapping_dict)\n",
    ")\n",
    "pat_at[\"assessment_value\"] = pat_at[\"numerical_value\"].combine_first(\n",
    "    pat_at[\"categorical_value\"]\n",
    ")\n",
    "pat_at.drop(columns=[\"numerical_value\", \"categorical_value\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at.assessment_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at['assessment_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_at.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = pc.load_data(\"clif_vitals\", -1)\n",
    "vit[\"hospitalization_id\"] = vit[\"hospitalization_id\"].astype(str)\n",
    "vit[\"hospitalization_id\"] = (\n",
    "    vit[\"hospitalization_id\"].map(hospitalization_to_block).astype(str)\n",
    ")\n",
    "vit_col = [\"hospitalization_id\", \"recorded_dttm_min\", \"vital_category\", \"vital_value\"]\n",
    "vit[\"vital_category\"] = vit[\"vital_category\"].str.lower()\n",
    "\n",
    "\n",
    "vit = pc.convert_datetime_columns_to_site_tz(vit, pc.helper[\"your_site_timezone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit[\"recorded_dttm_min\"] = pc.getdttm(vit[\"recorded_dttm\"])\n",
    "pc.deftime(vit[\"recorded_dttm_min\"])\n",
    "vit = vit[\n",
    "    (vit[\"hospitalization_id\"].isin(required_id))\n",
    "    & (\n",
    "        vit[\"vital_category\"].isin(\n",
    "            [\n",
    "                \"map\",\n",
    "                \"heart_rate\",\n",
    "                \"sbp\",\n",
    "                \"dbp\",\n",
    "                \"spo2\",\n",
    "                \"respiratory_rate\",\n",
    "                \"weight_kg\",\n",
    "                \"height_cm\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "][vit_col].reset_index(drop=True)\n",
    "\n",
    "# Sort by hospitalization_id and recorded_dttm\n",
    "vit = vit.sort_values(by=[\"hospitalization_id\", \"recorded_dttm_min\"])\n",
    "\n",
    "# Group by hospitalization_id, vital_category, and recorded_dttm_min, then take the first occurrence of vital_value\n",
    "vit = vit.groupby(\n",
    "    [\"hospitalization_id\", \"vital_category\", \"recorded_dttm_min\"], as_index=False\n",
    ").agg({\"vital_value\": \"first\"})\n",
    "# make sure float\n",
    "vit[\"vital_value\"] = vit[\"vital_value\"].astype(float)\n",
    "\n",
    "# for meds\n",
    "vit_weight = vit[vit[\"vital_category\"] == \"weight_kg\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicates\n",
    "duplicates = vit.duplicated(\n",
    "    subset=[\"hospitalization_id\", \"vital_category\", \"recorded_dttm_min\"], keep=False\n",
    ")\n",
    "\n",
    "# Show any duplicates (should be empty if grouping worked correctly)\n",
    "vit[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Med Unit Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_weight.rename(\n",
    "    {\"vital_category\": \"med_category\", \"recorded_dttm_min\": \"admin_dttm\"},\n",
    "    axis=\"columns\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "new_mac = pd.concat([mac, vit_weight], ignore_index=True)\n",
    "\n",
    "new_mac = new_mac.sort_values(by=[\"hospitalization_id\", \"admin_dttm\"])\n",
    "\n",
    "new_mac[\"vital_value\"] = (\n",
    "    new_mac.groupby(\"hospitalization_id\")[\"vital_value\"].ffill().bfill()\n",
    ")\n",
    "\n",
    "new_mac = new_mac[~(new_mac[\"med_category\"] == \"weight_kg\")].reset_index(drop=True)\n",
    "\n",
    "print(\"mac rows:\", mac.shape, \"New mac rows:\", new_mac.shape)\n",
    "# del vit_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mac.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The med_unit_info dictionary\n",
    "med_unit_info = {\n",
    "    'norepinephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'epinephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'phenylephrine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'angiotensin': {\n",
    "        'required_unit': 'ng/kg/min',\n",
    "        'acceptable_units': ['ng/kg/min', 'ng/kg/hr'],\n",
    "    },\n",
    "    'vasopressin': {\n",
    "        'required_unit': 'units/min',\n",
    "        'acceptable_units': ['units/min', 'units/hr', 'milliunits/min', 'milliunits/hr'],\n",
    "    },\n",
    "    'dopamine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'dobutamine': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'milrinone': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "    'isoproterenol': {\n",
    "        'required_unit': 'mcg/kg/min',\n",
    "        'acceptable_units': ['mcg/kg/min', 'mcg/kg/hr', 'mg/kg/hr', 'mcg/min', 'mg/hr'],\n",
    "    },\n",
    "}\n",
    "\n",
    "def convert_med_dose(row):\n",
    "    category = row['med_category']\n",
    "    # If the category is not in our dictionary, skip conversion.\n",
    "    if category not in med_unit_info:\n",
    "        return row\n",
    "    \n",
    "    info = med_unit_info[category]\n",
    "    required_unit = info['required_unit']\n",
    "    acceptable_units = info['acceptable_units']\n",
    "    \n",
    "    current_unit = row['med_dose_unit']\n",
    "    dose = row['med_dose']\n",
    "    weight = row['vital_value']  # patient's weight in kg\n",
    "\n",
    "    # If the current unit already matches the required unit, nothing to do.\n",
    "    if current_unit == required_unit:\n",
    "        return row\n",
    "\n",
    "    # If the current unit is not in the acceptable list, skip conversion.\n",
    "    if current_unit not in acceptable_units:\n",
    "        return row\n",
    "\n",
    "    # Start with a conversion factor of 1.\n",
    "    conversion_factor = 1.0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Weight conversion: if the current unit is per kg but the required is not,\n",
    "    # then multiply by the patient’s weight.\n",
    "    if 'kg' in current_unit and 'kg' not in required_unit:\n",
    "        conversion_factor *= weight\n",
    "    elif 'kg' not in current_unit and 'kg' in required_unit:\n",
    "        conversion_factor /= weight\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Time conversion: convert from per hour to per minute or vice versa.\n",
    "    if 'hr' in current_unit and 'min' in required_unit:\n",
    "        conversion_factor /= 60.0\n",
    "    elif 'min' in current_unit and 'hr' in required_unit:\n",
    "        conversion_factor *= 60.0\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Medication unit conversion (e.g., mg to mcg, milliunits to units)\n",
    "    # We assume the first part (before the first '/') is the measurement unit.\n",
    "    current_med_unit = current_unit.split('/')[0]\n",
    "    required_med_unit = required_unit.split('/')[0]\n",
    "\n",
    "    med_conversion = {\n",
    "        ('mg', 'mcg'): 1000,\n",
    "        ('mcg', 'mg'): 0.001,\n",
    "        ('milliunits', 'units'): 0.001,\n",
    "        ('units', 'milliunits'): 1000,\n",
    "    }\n",
    "\n",
    "    if current_med_unit != required_med_unit:\n",
    "        factor = med_conversion.get((current_med_unit, required_med_unit))\n",
    "        if factor is not None:\n",
    "            conversion_factor *= factor\n",
    "        else:\n",
    "            # If no conversion factor is defined, skip conversion.\n",
    "            return row\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Apply the conversion\n",
    "    new_dose = dose * conversion_factor\n",
    "\n",
    "    # Update the row with the converted dose and unit.\n",
    "    row['med_dose'] = new_dose\n",
    "    row['med_dose_unit'] = required_unit\n",
    "    return row\n",
    "\n",
    "# Apply the conversion function with tqdm for progress tracking\n",
    "tqdm.pandas(desc=\"Converting medication doses\")\n",
    "new_mac = new_mac.progress_apply(convert_med_dose, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table for each med_category\n",
    "summary_table = (\n",
    "    new_mac.groupby([\"med_category\", \"med_dose_unit\"])\n",
    "    .agg(\n",
    "        total_N=(\"med_category\", \"size\"),\n",
    "        min=(\"med_dose\", \"min\"),\n",
    "        max=(\"med_dose\", \"max\"),\n",
    "        first_quantile=(\"med_dose\", lambda x: x.quantile(0.25)),\n",
    "        second_quantile=(\"med_dose\", lambda x: x.quantile(0.5)),\n",
    "        third_quantile=(\"med_dose\", lambda x: x.quantile(0.75)),\n",
    "        missing_values=(\"med_dose\", lambda x: x.isna().sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "## check the distrbituon of required continuous meds\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.register(\"base\", base)\n",
    "duckdb.register(\"pat_at\", pat_at)\n",
    "duckdb.register(\"rst\", rst)\n",
    "duckdb.register(\"mac\", new_mac)\n",
    "duckdb.register('adt',adt)\n",
    "duckdb.register('vit',vit)\n",
    "\n",
    "q=\"\"\"\n",
    "WITH\n",
    "    uni_event_dttm as (\n",
    "        select distinct\n",
    "            hospitalization_id,\n",
    "            event_time\n",
    "        from\n",
    "            (\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    in_dttm AS event_time\n",
    "                FROM\n",
    "                    adt\n",
    "                where\n",
    "                    in_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm AS event_time\n",
    "                FROM\n",
    "                    rst\n",
    "                where\n",
    "                    recorded_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm AS event_time\n",
    "                FROM\n",
    "                    pat_at\n",
    "                where\n",
    "                    recorded_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    admin_dttm AS event_time\n",
    "                FROM\n",
    "                    mac\n",
    "                where\n",
    "                    admin_dttm is not null\n",
    "                UNION\n",
    "                SELECT\n",
    "                    hospitalization_id,\n",
    "                    recorded_dttm_min AS event_time\n",
    "                FROM\n",
    "                    vit\n",
    "                where\n",
    "                    recorded_dttm_min is not null\n",
    "            ) uni_time\n",
    "    )\n",
    "select distinct\n",
    "    patient_id,\n",
    "    a.hospitalization_id,\n",
    "    admission_dttm,\n",
    "    discharge_dttm,\n",
    "    age_at_admission,\n",
    "    discharge_category,\n",
    "    sex_category,\n",
    "    race_category,\n",
    "    ethnicity_category,\n",
    "    language_name,\n",
    "    event_time\n",
    "from\n",
    "    base a\n",
    "    left join uni_event_dttm b on a.hospitalization_id = b.hospitalization_id\n",
    "\"\"\"\n",
    "wide_cohort_df = duckdb.sql(q).df()\n",
    "pc.deftime(wide_cohort_df['event_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pivots for assessment and mac table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH pas_data AS (\n",
    "    SELECT  distinct assessment_value ,\tassessment_category\t,\n",
    "    hospitalization_id || '_' || strftime(recorded_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM pat_at where recorded_dttm is not null \n",
    ") \n",
    "PIVOT pas_data\n",
    "ON assessment_category\n",
    "USING first(assessment_value)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_pas = duckdb.sql(query).df()\n",
    "\n",
    "query = \"\"\"\n",
    "WITH mac_data AS (\n",
    "    SELECT  distinct med_dose ,\tmed_category\t,\n",
    "    hospitalization_id || '_' || strftime(admin_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM mac where admin_dttm is not null \n",
    ") \n",
    "PIVOT mac_data\n",
    "ON med_category\n",
    "USING min(med_dose)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_mac = duckdb.sql(query).df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "WITH vital_data AS (\n",
    "    SELECT  distinct vital_category,\tvital_value\t,\n",
    "    hospitalization_id || '_' || strftime(recorded_dttm_min, '%Y%m%d%H%M') AS combo_id\n",
    "    FROM vit where recorded_dttm_min is not null \n",
    ")\n",
    "PIVOT vital_data\n",
    "ON vital_category\n",
    "USING first(vital_value)\n",
    "GROUP BY combo_id\n",
    "\"\"\"\n",
    "p_vitals = duckdb.sql(query).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id-ing all unique timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.register(\"expanded_df\", wide_cohort_df)\n",
    "duckdb.register(\"p_pas\", p_pas)\n",
    "duckdb.register(\"p_mac\", p_mac)\n",
    "\n",
    "q=\"\"\"\n",
    "  WITH\n",
    "    u_rst as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (recorded_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            rst\n",
    "    ),\n",
    "    u_adt as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (in_dttm, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            adt\n",
    "    ),\n",
    "    u_expanded_df as (\n",
    "        select\n",
    "            *,\n",
    "            hospitalization_id || '_' || strftime (event_time, '%Y%m%d%H%M') AS combo_id\n",
    "        from\n",
    "            expanded_df\n",
    "    )\n",
    "select\n",
    "    *\n",
    "from\n",
    "    u_expanded_df a\n",
    "    left join u_adt d on a.combo_id = d.combo_id\n",
    "    left join u_rst e on a.combo_id = e.combo_id\n",
    "    left join p_mac g on a.combo_id = g.combo_id\n",
    "    left join p_pas h on a.combo_id = h.combo_id\n",
    "    left join p_vitals i on a.combo_id=i.combo_id \n",
    "\n",
    "                    \n",
    "\"\"\"\n",
    "\n",
    "all_join_df = duckdb.sql(q).df().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_join_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cohort_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_join_df.drop(columns= ['hospitalization_id_2','hospitalization_id_3','combo_id', 'combo_id_2' ,'combo_id_3','combo_id_4','combo_id_5','recorded_dttm','combo_id_6','in_dttm'], axis = 1,inplace=True)\n",
    "\n",
    "all_join_df[\"event_time\"] = pd.to_datetime(all_join_df[\"event_time\"])\n",
    "all_join_df[\"date\"] = all_join_df[\"event_time\"].dt.date\n",
    "\n",
    "all_join_df = all_join_df.sort_values([\"hospitalization_id\", \"event_time\"]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# Assign day numbers to each 'hospitalization_id'\n",
    "all_join_df[\"day_number\"] = (\n",
    "    all_join_df.groupby(\"hospitalization_id\")[\"date\"].rank(method=\"dense\").astype(int)\n",
    ")\n",
    "\n",
    "# Create the combo_key by combining 'hospitalization_id' and 'day_number'\n",
    "all_join_df[\"hosp_id_day_key\"] = (\n",
    "    all_join_df[\"hospitalization_id\"].astype(str)\n",
    "    + \"_day_\"\n",
    "    + all_join_df[\"day_number\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SAT SBT columns check\n",
    "\n",
    "columns_to_check = [\n",
    "    \"sbt_delivery_pass_fail\",\n",
    "    \"sbt_screen_pass_fail\",\n",
    "    \"sat_delivery_pass_fail\",\n",
    "    \"sat_screen_pass_fail\",\n",
    "    \"rass\",\n",
    "    \"gcs_total\",\n",
    "]\n",
    "\n",
    "for col in columns_to_check:\n",
    "    if col not in all_join_df.columns:\n",
    "        all_join_df[col] = np.nan\n",
    "        print(\n",
    "            f\"Column '{col}' is missing for your site. Filling with NaN for now. If this is unintended, please verify your data element.\"\n",
    "        )\n",
    "\n",
    "## meds check\n",
    "\n",
    "meds_check = [\n",
    "    \"norepinephrine\",\n",
    "    \"epinephrine\",\n",
    "    \"phenylephrine\",\n",
    "    \"angiotensin\",\n",
    "    \"vasopressin\",\n",
    "    \"dopamine\",\n",
    "    \"dobutamine\",\n",
    "    \"milrinone\",\n",
    "    \"isoproterenol\",\n",
    "    \"cisatracurium\",\n",
    "    \"vecuronium\",\n",
    "    \"rocuronium\",\n",
    "    \"fentanyl\",\n",
    "    \"propofol\",\n",
    "    \"lorazepam\",\n",
    "    \"midazolam\",\n",
    "    \"hydromorphone\",\n",
    "    \"morphine\",\n",
    "]\n",
    "\n",
    "for col in meds_check:\n",
    "    if col not in all_join_df.columns:\n",
    "        all_join_df[col] = np.nan\n",
    "        print(\n",
    "            f\"mCide: '{col}' is missing. Please check your CLIF Meds table, it's can be missing if your site doesn't use it.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_join_df.to_csv('../output/intermediate/study_cohort.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.path.join(\"../output/final/\", pc.helper[\"site_name\"])\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"Directory '{directory_path}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cohort creation completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".SBT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
